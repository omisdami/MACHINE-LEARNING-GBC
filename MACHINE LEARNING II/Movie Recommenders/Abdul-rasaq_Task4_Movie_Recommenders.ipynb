{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommender Systems\n",
    "\n",
    "This notebook implements various movie recommendation approaches:\n",
    "1. Popularity-based\n",
    "2. Content-based Filtering\n",
    "3. Collaborative Filtering\n",
    "4. Matrix Factorization\n",
    "5. Hybrid Approach\n",
    "\n",
    "Source: https://grouplens.org/datasets/movielens/20m/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from surprise import Dataset, Reader, SVD\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "from functools import lru_cache\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from scipy import sparse\n",
    "import h5py\n",
    "import joblib\n",
    "import psutil\n",
    "from pathlib import Path\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple Metal device: mps\n"
     ]
    }
   ],
   "source": [
    "# Setup device and optimizations for Apple Silicon\n",
    "device = torch.device('mps')\n",
    "torch.backends.mps.enable_fallback_kernels = True\n",
    "print(f\"Using Apple Metal device: {device}\")\n",
    "\n",
    "# Advanced caching mechanism\n",
    "class RecommendationCache:\n",
    "    def __init__(self, max_size=1000):\n",
    "        self.cache = {}\n",
    "        self.max_size = max_size\n",
    "    \n",
    "    @lru_cache(maxsize=1000)\n",
    "    def get_movie_features(self, movie_idx):\n",
    "        return self.latent_matrix_gpu[movie_idx]\n",
    "    \n",
    "    def get(self, key):\n",
    "        return self.cache.get(key)\n",
    "    \n",
    "    def set(self, key, value):\n",
    "        if len(self.cache) >= self.max_size:\n",
    "            self.cache.pop(next(iter(self.cache)))\n",
    "        self.cache[key] = value\n",
    "\n",
    "cache = RecommendationCache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate chunk size based on available memory\n",
    "def get_optimal_chunk_size():\n",
    "    available_mem = psutil.virtual_memory().available\n",
    "    # Use 20% of available memory for chunk size\n",
    "    return int((available_mem * 0.2) / (8 * 1024))\n",
    "\n",
    "# Read datasets in chunks with disk caching\n",
    "def read_chunked_csv(filename, chunksize=None):\n",
    "    cache_file = Path(f\".cache_{Path(filename).stem}.joblib\")\n",
    "    if cache_file.exists():\n",
    "        return joblib.load(cache_file)\n",
    "    \n",
    "    chunksize = chunksize or get_optimal_chunk_size()\n",
    "    chunks = []\n",
    "    total_rows = sum(1 for _ in open(filename)) - 1  # Subtract header\n",
    "    \n",
    "    with tqdm(total=total_rows, desc=f\"Loading {filename}\") as pbar:\n",
    "        for chunk in pd.read_csv(filename, chunksize=chunksize):\n",
    "            chunks.append(chunk)\n",
    "            pbar.update(len(chunk))\n",
    "    \n",
    "    result = pd.concat(chunks)\n",
    "    joblib.dump(result, cache_file)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading movies...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loading movies...\")\n",
    "movies_df = pd.read_csv('ml-20m/movies.csv')\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27278 entries, 0 to 27277\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   movieId  27278 non-null  int64 \n",
      " 1   title    27278 non-null  object\n",
      " 2   genres   27278 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 639.5+ KB\n"
     ]
    }
   ],
   "source": [
    "movies_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ratings...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112486027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1        2     3.5  1112486027\n",
       "1       1       29     3.5  1112484676\n",
       "2       1       32     3.5  1112484819\n",
       "3       1       47     3.5  1112484727\n",
       "4       1       50     3.5  1112484580"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loading ratings...\")\n",
    "ratings_df = read_chunked_csv('ml-20m/ratings.csv')\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000263 entries, 0 to 20000262\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   userId     int64  \n",
      " 1   movieId    int64  \n",
      " 2   rating     float64\n",
      " 3   timestamp  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 610.4 MB\n"
     ]
    }
   ],
   "source": [
    "ratings_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tags...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>tag</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>4141</td>\n",
       "      <td>Mark Waters</td>\n",
       "      <td>1240597180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65</td>\n",
       "      <td>208</td>\n",
       "      <td>dark hero</td>\n",
       "      <td>1368150078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65</td>\n",
       "      <td>353</td>\n",
       "      <td>dark hero</td>\n",
       "      <td>1368150079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65</td>\n",
       "      <td>521</td>\n",
       "      <td>noir thriller</td>\n",
       "      <td>1368149983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "      <td>592</td>\n",
       "      <td>dark hero</td>\n",
       "      <td>1368150078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId            tag   timestamp\n",
       "0      18     4141    Mark Waters  1240597180\n",
       "1      65      208      dark hero  1368150078\n",
       "2      65      353      dark hero  1368150079\n",
       "3      65      521  noir thriller  1368149983\n",
       "4      65      592      dark hero  1368150078"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loading tags...\")\n",
    "tags_df = read_chunked_csv('ml-20m/tags.csv')\n",
    "tags_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 465564 entries, 0 to 465563\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   userId     465564 non-null  int64 \n",
      " 1   movieId    465564 non-null  int64 \n",
      " 2   tag        465548 non-null  object\n",
      " 3   timestamp  465564 non-null  int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 14.2+ MB\n"
     ]
    }
   ],
   "source": [
    "tags_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing tags...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "643"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process tags in chunks\n",
    "print(\"Processing tags...\")\n",
    "tags_df['tag'] = tags_df['tag'].fillna('').astype(str)\n",
    "tags_grouped = tags_df.groupby('movieId')['tag'].apply(\n",
    "    lambda x: ' '.join(x[:1000] if len(x) > 1000 else x)\n",
    ").reset_index()\n",
    "\n",
    "# Merge and clean up\n",
    "movies_with_tags = pd.merge(movies_df, tags_grouped, on='movieId', how='left')\n",
    "movies_with_tags['tag'] = movies_with_tags['tag'].fillna('')\n",
    "\n",
    "# Clean up memory\n",
    "del tags_df, tags_grouped\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Popularity-based Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popularity_recommender(n_recommendations=10):\n",
    "    # Calculate mean rating and number of ratings for each movie\n",
    "    movie_stats = ratings_df.groupby('movieId').agg({\n",
    "        'rating': ['count', 'mean']\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Rename columns\n",
    "    movie_stats.columns = ['movieId', 'rating_count', 'rating_mean']\n",
    "    \n",
    "    # Filter movies with minimum number of ratings (e.g., 100)\n",
    "    popular_movies = movie_stats[movie_stats['rating_count'] >= 100]\n",
    "    \n",
    "    # Sort by rating mean and count\n",
    "    popular_movies = popular_movies.sort_values(['rating_mean', 'rating_count'], ascending=[False, False])\n",
    "    \n",
    "    # Get movie titles\n",
    "    recommendations = pd.merge(popular_movies, movies_df, on='movieId')\n",
    "    \n",
    "    return recommendations[['movieId', 'title', 'rating_mean', 'rating_count', 'genres']].head(n_recommendations) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Content-based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing TF-IDF in batches...\n"
     ]
    }
   ],
   "source": [
    "def process_tfidf_in_batches(texts, batch_size=1000):\n",
    "    cache_file = Path(\".cache_tfidf.h5\")\n",
    "    if cache_file.exists():\n",
    "        with h5py.File(cache_file, 'r') as f:\n",
    "            return torch.tensor(f['latent_matrix'][()], device=device)\n",
    "    \n",
    "    print(\"Creating TF-IDF vectors...\")\n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    \n",
    "    # First pass to fit vocabulary\n",
    "    print(\"Fitting TF-IDF vocabulary...\")\n",
    "    tfidf.fit(texts)\n",
    "    \n",
    "    # Process in batches\n",
    "    n_batches = (len(texts) + batch_size - 1) // batch_size\n",
    "    latent_matrices = []\n",
    "    \n",
    "    for i in tqdm(range(n_batches), desc=\"Processing TF-IDF batches\"):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = min((i + 1) * batch_size, len(texts))\n",
    "        batch_texts = texts[start_idx:end_idx]\n",
    "        \n",
    "        # Transform batch and keep sparse\n",
    "        batch_tfidf = tfidf.transform(batch_texts)\n",
    "        \n",
    "        # Compute SVD for batch with explicit float32 dtype for MPS compatibility\n",
    "        batch_U, batch_S, batch_V = torch.svd(\n",
    "            torch.tensor(batch_tfidf.toarray(), device=device, dtype=torch.float32)\n",
    "        )\n",
    "        batch_latent = (batch_U[:, :100] @ torch.diag(batch_S[:100]))\n",
    "        latent_matrices.append(batch_latent.cpu().numpy())\n",
    "    \n",
    "    # Combine results\n",
    "    latent_matrix = np.vstack(latent_matrices)\n",
    "    \n",
    "    # Cache results\n",
    "    with h5py.File(cache_file, 'w') as f:\n",
    "        f.create_dataset('latent_matrix', data=latent_matrix)\n",
    "    \n",
    "    return torch.tensor(latent_matrix, device=device)\n",
    "\n",
    "print(\"Processing TF-IDF in batches...\")\n",
    "latent_matrix_gpu = process_tfidf_in_batches(movies_with_tags['tag'])\n",
    "\n",
    "# Cache for frequently accessed movie features\n",
    "@lru_cache(maxsize=1000)\n",
    "def get_cached_movie_features(movie_idx):\n",
    "    return latent_matrix_gpu[movie_idx]\n",
    "\n",
    "def content_based_recommender(movie_title, n_recommendations=10):\n",
    "    # Get movie index and features from cache\n",
    "    movie_idx = movies_with_tags[movies_with_tags['title'] == movie_title].index[0]\n",
    "    query_vector = get_cached_movie_features(movie_idx)\n",
    "    \n",
    "    # Batch compute similarities using optimized operations\n",
    "    similarities = torch.nn.functional.cosine_similarity(\n",
    "        query_vector.unsqueeze(0).unsqueeze(0),\n",
    "        latent_matrix_gpu.unsqueeze(0)\n",
    "    ).squeeze()\n",
    "    \n",
    "    # Get top recommendations using MPS-optimized topk\n",
    "    _, similar_indices = similarities.topk(n_recommendations + 1)\n",
    "    similar_indices = similar_indices[1:].cpu().numpy()\n",
    "    \n",
    "    # Cache the results\n",
    "    cache.set(f\"content_{movie_title}\", similar_indices)\n",
    "    \n",
    "    recommendations = movies_with_tags.iloc[similar_indices][['movieId', 'title', 'genres']]                                                                      \n",
    "    recommendations['title'] = recommendations['title'].str.ljust(50)                                                                                   \n",
    "    return recommendations  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating user-movie matrix...\n",
      "Creating sparse user-movie matrix...\n",
      "Performing collaborative filtering SVD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Progress: 100%|██████████| 1/1 [00:06<00:00,  6.97s/it]\n"
     ]
    }
   ],
   "source": [
    "def create_sparse_matrix(ratings_df, batch_size=100000):\n",
    "    print(\"Creating sparse user-movie matrix...\")\n",
    "    cache_file = Path(\".cache_collab.npz\")\n",
    "    cache_maps = Path(\".cache_collab_maps.joblib\")\n",
    "    \n",
    "    if cache_file.exists() and cache_maps.exists():\n",
    "        matrix = sparse.load_npz(cache_file)\n",
    "        cache_data = joblib.load(cache_maps)\n",
    "        if len(cache_data) == 2:  # Old cache format\n",
    "            user_map, movie_map = cache_data\n",
    "            movie_ids = list(movie_map.keys())\n",
    "        else:  # New cache format\n",
    "            user_map, movie_map, movie_ids = cache_data\n",
    "        return matrix, user_map, movie_map, movie_ids\n",
    "    \n",
    "    rows, cols, data = [], [], []\n",
    "    user_map = {}\n",
    "    movie_map = {}\n",
    "    movie_ids = []\n",
    "    \n",
    "    # Process in batches\n",
    "    total_rows = len(ratings_df)\n",
    "    with tqdm(total=total_rows, desc=\"Building sparse matrix\") as pbar:\n",
    "        for start in range(0, total_rows, batch_size):\n",
    "            batch = ratings_df.iloc[start:start + batch_size]\n",
    "            \n",
    "            for _, row in batch.iterrows():\n",
    "                if row['userId'] not in user_map:\n",
    "                    user_map[row['userId']] = len(user_map)\n",
    "                if row['movieId'] not in movie_map:\n",
    "                    movie_map[row['movieId']] = len(movie_map)\n",
    "                    movie_ids.append(row['movieId'])\n",
    "                \n",
    "                rows.append(user_map[row['userId']])\n",
    "                cols.append(movie_map[row['movieId']])\n",
    "                data.append(row['rating'])\n",
    "                \n",
    "            pbar.update(len(batch))\n",
    "    \n",
    "    matrix = sparse.csr_matrix((data, (rows, cols)), \n",
    "                              shape=(len(user_map), len(movie_map)))\n",
    "    \n",
    "    # Cache the results\n",
    "    sparse.save_npz(cache_file, matrix)\n",
    "    joblib.dump((user_map, movie_map, movie_ids), cache_maps)\n",
    "    \n",
    "    return matrix, user_map, movie_map, movie_ids\n",
    "\n",
    "print(\"Creating user-movie matrix...\")\n",
    "user_movie_matrix, user_map, movie_map, movie_ids = create_sparse_matrix(ratings_df)\n",
    "\n",
    "print(\"Performing collaborative filtering SVD...\")\n",
    "with tqdm(total=1, desc=\"SVD Progress\") as pbar:\n",
    "    svd_collab = TruncatedSVD(n_components=100)\n",
    "    latent_matrix_2 = svd_collab.fit_transform(user_movie_matrix)\n",
    "    pbar.update(1)\n",
    "\n",
    "# Convert matrices to GPU tensors once\n",
    "latent_matrix_2_gpu = torch.tensor(latent_matrix_2, device=device, dtype=torch.float32)\n",
    "components_gpu = torch.tensor(svd_collab.components_, device=device, dtype=torch.float32)\n",
    "\n",
    "@lru_cache(maxsize=1000)\n",
    "def get_user_predictions(user_id, batch_size=10000):\n",
    "    # Get user's latent features\n",
    "    user_idx = user_map[user_id]\n",
    "    user_features = latent_matrix_2_gpu[user_idx]\n",
    "    \n",
    "    # Get user's rated movies for masking\n",
    "    rated_movies = set(ratings_df[ratings_df['userId'] == user_id]['movieId'])\n",
    "    \n",
    "    # Process predictions in batches\n",
    "    all_predictions = []\n",
    "    n_movies = len(movie_ids)\n",
    "    \n",
    "    for start_idx in range(0, n_movies, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, n_movies)\n",
    "        batch_components = components_gpu[:, start_idx:end_idx]\n",
    "        \n",
    "        # Calculate batch predictions\n",
    "        batch_predictions = torch.matmul(user_features, batch_components)\n",
    "        \n",
    "        # Mask rated movies in this batch\n",
    "        batch_movie_ids = movie_ids[start_idx:end_idx]\n",
    "        mask = torch.tensor([mid not in rated_movies for mid in batch_movie_ids], \n",
    "                          device=device, dtype=torch.bool)\n",
    "        \n",
    "        batch_predictions = torch.where(mask, batch_predictions,\n",
    "                                       torch.tensor(float('-inf'), device=device))\n",
    "        all_predictions.append(batch_predictions)\n",
    "    \n",
    "    return torch.cat(all_predictions)\n",
    "\n",
    "def collaborative_recommender(user_id, n_recommendations=10):\n",
    "    # Get cached predictions\n",
    "    predictions = get_user_predictions(user_id)\n",
    "    \n",
    "    # Get top recommendations\n",
    "    _, indices = torch.topk(predictions, n_recommendations)\n",
    "    top_movie_ids = [movie_ids[i] for i in indices.cpu().numpy()]\n",
    "    \n",
    "    # Get recommended movies\n",
    "    recommendations = movies_df[movies_df['movieId'].isin(top_movie_ids)]\n",
    "    return recommendations[['movieId', 'title', 'genres']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Matrix Factorization using Surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVD model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Training: 100%|██████████| 1/1 [01:19<00:00, 79.98s/it]\n"
     ]
    }
   ],
   "source": [
    "print(\"Training SVD model...\")\n",
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "trainset = Dataset.load_from_df(ratings_df[['userId', 'movieId', 'rating']], reader).build_full_trainset()\n",
    "svd_model = SVD(n_factors=100, random_state=17)\n",
    "with tqdm(total=1, desc=\"SVD Training\") as pbar:\n",
    "    svd_model.fit(trainset)\n",
    "    pbar.update(1)\n",
    "\n",
    "# Convert SVD matrices to GPU tensors once\n",
    "svd_pu = torch.tensor(svd_model.pu, device=device, dtype=torch.float32)\n",
    "svd_qi = torch.tensor(svd_model.qi, device=device, dtype=torch.float32)\n",
    "svd_bu = torch.tensor(svd_model.bu, device=device, dtype=torch.float32)\n",
    "svd_bi = torch.tensor(svd_model.bi, device=device, dtype=torch.float32)\n",
    "svd_mu = torch.tensor([svd_model.trainset.global_mean], device=device, dtype=torch.float32)\n",
    "\n",
    "def matrix_factorization_recommender(user_id, n_recommendations=10, batch_size=10000):\n",
    "    # Get all movies that are in the trainset\n",
    "    all_movies = set(svd_model.trainset._raw2inner_id_items.keys())\n",
    "    \n",
    "    # Get user's rated movies\n",
    "    rated_movies = ratings_df[ratings_df['userId'] == user_id]['movieId'].unique()\n",
    "    \n",
    "    # Get unrated movies that are in the trainset\n",
    "    unrated_movies = np.array(list(all_movies - set(rated_movies)))\n",
    "    \n",
    "    # Get user index in SVD model\n",
    "    user_inner_id = svd_model.trainset.to_inner_uid(user_id)\n",
    "    \n",
    "    # Get user factors and bias\n",
    "    user_factors = svd_pu[user_inner_id]\n",
    "    user_bias = svd_bu[user_inner_id]\n",
    "    \n",
    "    # Process movies in batches\n",
    "    all_predictions = []\n",
    "    for i in range(0, len(unrated_movies), batch_size):\n",
    "        batch_movies = unrated_movies[i:i + batch_size]\n",
    "        \n",
    "        # Get batch factors and biases\n",
    "        movie_factors = svd_qi[batch_movies]\n",
    "        movie_biases = svd_bi[batch_movies]\n",
    "        \n",
    "        # Calculate predictions for batch\n",
    "        batch_predictions = torch.matmul(user_factors, movie_factors.T) + user_bias + movie_biases + svd_mu\n",
    "        all_predictions.append(batch_predictions)\n",
    "    \n",
    "    # Combine all predictions\n",
    "    predictions = torch.cat(all_predictions)\n",
    "    \n",
    "    # Get top recommendations\n",
    "    _, indices = torch.topk(predictions, n_recommendations)\n",
    "    recommended_movie_ids = [unrated_movies[idx] for idx in indices.cpu().numpy()]\n",
    "    \n",
    "    # Get recommended movies\n",
    "    recommended_movies = movies_df[movies_df['movieId'].isin(recommended_movie_ids)]\n",
    "    return recommended_movies[['movieId', 'title', 'genres']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hybrid Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def compute_content_scores(movie_idx, all_movie_features):\n",
    "    query_vector = get_cached_movie_features(movie_idx)\n",
    "    return torch.nn.functional.cosine_similarity(\n",
    "        query_vector.unsqueeze(0).unsqueeze(0),\n",
    "        all_movie_features.unsqueeze(0)\n",
    "    ).squeeze()\n",
    "\n",
    "async def compute_collab_scores(user_features, components_gpu):\n",
    "    return torch.matmul(user_features, components_gpu)\n",
    "\n",
    "async def compute_mf_scores(user_inner_id, user_factors, all_movie_factors, all_movie_biases):\n",
    "    return torch.matmul(user_factors, all_movie_factors.T) + svd_bu[user_inner_id] + all_movie_biases + svd_mu\n",
    "\n",
    "async def hybrid_recommender(user_id, movie_title, n_recommendations=10):\n",
    "    # Get movie index for content-based\n",
    "    movie_idx = movies_with_tags[movies_with_tags['title'] == movie_title].index[0]\n",
    "    \n",
    "    # Get user features for collaborative\n",
    "    user_idx = user_map[user_id]\n",
    "    user_features = latent_matrix_2_gpu[user_idx]\n",
    "    user_ratings = torch.tensor(user_movie_matrix[user_idx].toarray()[0], device=device, dtype=torch.float32)\n",
    "    \n",
    "    # Get all valid movie indices\n",
    "    all_movies = set(svd_model.trainset._raw2inner_id_items.keys())\n",
    "    rated_movies = ratings_df[ratings_df['userId'] == user_id]['movieId'].unique()\n",
    "    unrated_movies = np.array(list(all_movies - set(rated_movies)))\n",
    "    \n",
    "    # Map movie IDs to indices\n",
    "    movie_id_to_idx = {mid: idx for idx, mid in enumerate(movies_df['movieId'])}\n",
    "    movie_indices = np.array([movie_id_to_idx[mid] for mid in unrated_movies])\n",
    "    \n",
    "    # Get all movie features first\n",
    "    all_movie_features = latent_matrix_gpu\n",
    "    \n",
    "    # Run all predictions concurrently\n",
    "    user_inner_id = svd_model.trainset.to_inner_uid(user_id)\n",
    "    user_factors = svd_pu[user_inner_id]\n",
    "    all_movie_factors = svd_qi\n",
    "    all_movie_biases = svd_bi\n",
    "    \n",
    "    content_task = compute_content_scores(movie_idx, all_movie_features)\n",
    "    collab_task = compute_collab_scores(user_features, components_gpu)\n",
    "    mf_task = compute_mf_scores(user_inner_id, user_factors, all_movie_factors, all_movie_biases)\n",
    "    \n",
    "    # Wait for all tasks to complete\n",
    "    all_content_similarities, all_collab_predictions, all_mf_predictions = await asyncio.gather(\n",
    "        content_task, collab_task, mf_task\n",
    "    )\n",
    "    \n",
    "    # Extract scores for unrated movies only\n",
    "    content_similarities = all_content_similarities[movie_indices]\n",
    "    collab_predictions = all_collab_predictions[movie_indices]\n",
    "    mf_predictions = all_mf_predictions[movie_indices]\n",
    "    \n",
    "    # Verify tensor sizes match\n",
    "    print(f\"Sizes - Content: {content_similarities.size()}, Collab: {collab_predictions.size()}, MF: {mf_predictions.size()}\")\n",
    "    \n",
    "    # Normalize scores to [0,1] range for each set of predictions\n",
    "    content_scores = (content_similarities - content_similarities.min()) / (content_similarities.max() - content_similarities.min())\n",
    "    collab_scores = (collab_predictions - collab_predictions.min()) / (collab_predictions.max() - collab_predictions.min())\n",
    "    mf_scores = (mf_predictions - mf_predictions.min()) / (mf_predictions.max() - mf_predictions.min())\n",
    "    \n",
    "    # Combine scores with weights\n",
    "    combined_scores = content_scores * 0.3 + collab_scores * 0.4 + mf_scores * 0.3\n",
    "    \n",
    "    # Get top recommendations\n",
    "    _, top_indices = combined_scores.topk(n_recommendations)\n",
    "    top_indices = top_indices.cpu().numpy()\n",
    "    \n",
    "    # Get recommended movies\n",
    "    recommended_movie_ids = unrated_movies[top_indices]\n",
    "    recommended_movies = movies_df[movies_df['movieId'].isin(recommended_movie_ids)].copy()\n",
    "    recommended_movies['scores'] = combined_scores[top_indices].cpu().numpy()\n",
    "    recommended_movies['content_score'] = content_scores[top_indices].cpu().numpy()\n",
    "    recommended_movies['collab_score'] = collab_scores[top_indices].cpu().numpy()\n",
    "    recommended_movies['mf_score'] = mf_scores[top_indices].cpu().numpy()\n",
    "    \n",
    "    # Cache the results\n",
    "    cache.set(f\"hybrid_{user_id}_{movie_title}\", recommended_movie_ids)\n",
    "    \n",
    "    return recommended_movies.sort_values('scores', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluation Metrics\n",
    "\n",
    "The following metrics show predicted ratings for recommended movies to help evaluate recommendation quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popular Movies:\n",
      "|   movieId | title                                         |   rating_mean |   rating_count | genres                  |   predicted_rating |\n",
      "|----------:|:----------------------------------------------|--------------:|---------------:|:------------------------|-------------------:|\n",
      "|       318 | Shawshank Redemption, The (1994)              |       4.44699 |          63366 | Crime|Drama             |               4.35 |\n",
      "|       858 | Godfather, The (1972)                         |       4.36473 |          41355 | Crime|Drama             |               3.86 |\n",
      "|        50 | Usual Suspects, The (1995)                    |       4.33437 |          47006 | Crime|Mystery|Thriller  |               4.05 |\n",
      "|       527 | Schindler's List (1993)                       |       4.31018 |          50054 | Drama|War               |               4.09 |\n",
      "|      1221 | Godfather: Part II, The (1974)                |       4.27564 |          27398 | Crime|Drama             |               3.82 |\n",
      "|      2019 | Seven Samurai (Shichinin no samurai) (1954)   |       4.27418 |          11611 | Action|Adventure|Drama  |               3.81 |\n",
      "|       904 | Rear Window (1954)                            |       4.27133 |          17449 | Mystery|Thriller        |               3.91 |\n",
      "|      7502 | Band of Brothers (2001)                       |       4.26318 |           4305 | Action|Drama|War        |               4.07 |\n",
      "|       912 | Casablanca (1942)                             |       4.25833 |          24349 | Drama|Romance           |               3.83 |\n",
      "|       922 | Sunset Blvd. (a.k.a. Sunset Boulevard) (1950) |       4.25693 |           6525 | Drama|Film-Noir|Romance |               3.7  |\n",
      "\n",
      "Content-based Recommendations for 'Toy Story (1995)':\n",
      "|   movieId | title                          | genres                             |   predicted_rating |\n",
      "|----------:|:-------------------------------|:-----------------------------------|-------------------:|\n",
      "|         2 | Jumanji (1995)                 | Adventure|Children|Fantasy         |               3.92 |\n",
      "|        17 | Sense and Sensibility (1995)   | Drama|Romance                      |               3.81 |\n",
      "|        21 | Get Shorty (1995)              | Comedy|Crime|Thriller              |               3.35 |\n",
      "|        15 | Cutthroat Island (1995)        | Action|Adventure|Romance           |               3.53 |\n",
      "|        20 | Money Train (1995)             | Action|Comedy|Crime|Drama|Thriller |               3.39 |\n",
      "|        57 | Home for the Holidays (1995)   | Drama                              |               3.62 |\n",
      "|        11 | American President, The (1995) | Comedy|Drama|Romance               |               3.81 |\n",
      "|        50 | Usual Suspects, The (1995)     | Crime|Mystery|Thriller             |               4.05 |\n",
      "|        24 | Powder (1995)                  | Drama|Sci-Fi                       |               3.91 |\n",
      "|        43 | Restoration (1995)             | Drama                              |               3.72 |\n",
      "\n",
      "Collaborative Filtering Recommendations for user 1:\n",
      "|   movieId | title                                             | genres                                                    |   predicted_rating |\n",
      "|----------:|:--------------------------------------------------|:----------------------------------------------------------|-------------------:|\n",
      "|      1073 | Willy Wonka & the Chocolate Factory (1971)        | Children|Comedy|Fantasy|Musical                           |               3.78 |\n",
      "|      1206 | Clockwork Orange, A (1971)                        | Crime|Drama|Sci-Fi|Thriller                               |               3.48 |\n",
      "|      1210 | Star Wars: Episode VI - Return of the Jedi (1983) | Action|Adventure|Sci-Fi                                   |               4.23 |\n",
      "|      1225 | Amadeus (1984)                                    | Drama                                                     |               3.84 |\n",
      "|      1275 | Highlander (1986)                                 | Action|Adventure|Fantasy                                  |               4.04 |\n",
      "|      2005 | Goonies, The (1985)                               | Action|Adventure|Children|Comedy|Fantasy                  |               3.81 |\n",
      "|      2115 | Indiana Jones and the Temple of Doom (1984)       | Action|Adventure|Fantasy                                  |               3.93 |\n",
      "|      2161 | NeverEnding Story, The (1984)                     | Adventure|Children|Fantasy                                |               3.97 |\n",
      "|      2987 | Who Framed Roger Rabbit? (1988)                   | Adventure|Animation|Children|Comedy|Crime|Fantasy|Mystery |               3.63 |\n",
      "|      6874 | Kill Bill: Vol. 1 (2003)                          | Action|Crime|Thriller                                     |               3.88 |\n",
      "\n",
      "Matrix Factorization Recommendations for user 1:\n",
      "|   movieId | title                                                   | genres                    |   predicted_rating |\n",
      "|----------:|:--------------------------------------------------------|:--------------------------|-------------------:|\n",
      "|       158 | Casper (1995)                                           | Adventure|Children        |               3.6  |\n",
      "|      6602 | Brain Damage (1988)                                     | Comedy|Horror             |               3.3  |\n",
      "|     27526 | Deadline (Sprängaren) (2001)                            | Drama|Thriller            |               3.51 |\n",
      "|     38095 | Bittersweet Life, A (Dalkomhan insaeng) (2005)          | Action|Crime|Drama        |               3.89 |\n",
      "|     38159 | Short Film About Love, A (Krótki film o milosci) (1988) | Drama|Romance             |               3.84 |\n",
      "|     99089 | Poor Little Rich Girl (1936)                            | Adventure|Musical|Romance |               3.58 |\n",
      "|     99108 | Girl on a Motorcycle, The (1968)                        | Drama|Romance             |               3.67 |\n",
      "|     99110 | Save the Date (2012)                                    | Comedy|Romance            |               3.78 |\n",
      "|     99114 | Django Unchained (2012)                                 | Action|Drama|Western      |               4.02 |\n",
      "|     99210 | Seven Ways from Sundown (1960)                          | Action|Adventure|Western  |               3.74 |\n",
      "\n",
      "Hybrid Recommendations for user 1 and 'Toy Story (1995)':\n",
      "Sizes - Content: torch.Size([26569]), Collab: torch.Size([26569]), MF: torch.Size([26569])\n",
      "|   movieId | title                              | genres                                      |   scores |   content_score |   collab_score |   mf_score |   predicted_rating |\n",
      "|----------:|:-----------------------------------|:--------------------------------------------|---------:|----------------:|---------------:|-----------:|-------------------:|\n",
      "|         1 | Toy Story (1995)                   | Adventure|Animation|Children|Comedy|Fantasy |      nan |             nan |       0.465249 |   0.140364 |               4.01 |\n",
      "|         3 | Grumpier Old Men (1995)            | Comedy|Romance                              |      nan |             nan |       0.630033 |   0.876867 |               3.36 |\n",
      "|         4 | Waiting to Exhale (1995)           | Comedy|Drama|Romance                        |      nan |             nan |       0.730675 |   0.860745 |               3.29 |\n",
      "|         5 | Father of the Bride Part II (1995) | Comedy                                      |      nan |             nan |       0.769519 |   0.872507 |               3.45 |\n",
      "|         6 | Heat (1995)                        | Action|Crime|Thriller                       |      nan |             nan |       0.847728 |   0.899922 |               3.73 |\n",
      "|         7 | Sabrina (1995)                     | Comedy|Romance                              |      nan |             nan |       0.516175 |   0.835802 |               3.7  |\n",
      "|         8 | Tom and Huck (1995)                | Adventure|Children                          |      nan |             nan |       0.572486 |   0.856701 |               3.54 |\n",
      "|         9 | Sudden Death (1995)                | Action                                      |      nan |             nan |       0.506579 |   0.822912 |               3.51 |\n",
      "|        10 | GoldenEye (1995)                   | Action|Adventure|Thriller                   |      nan |             nan |       0.704012 |   0.881728 |               3.7  |\n",
      "|    131072 | Jesus liebt mich (2012)            | Comedy                                      |      nan |             nan |       0.735127 |   0.967061 |               3.49 |\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tabulate import tabulate\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "def predict_ratings(user_id, movie_ids):\n",
    "    \"\"\"Predict ratings for given user and movies using SVD model\"\"\"\n",
    "    predictions = []\n",
    "    for movie_id in movie_ids:\n",
    "        try:\n",
    "            pred = svd_model.predict(user_id, movie_id).est\n",
    "            predictions.append(round(pred, 2))\n",
    "        except:\n",
    "            predictions.append(None)\n",
    "    return predictions\n",
    "\n",
    "def display_recommendations(df, show_index=False, user_id=None):\n",
    "    \"\"\"Display recommendations with predicted ratings if user_id is provided\"\"\"\n",
    "    if user_id is not None and 'movieId' in df.columns:\n",
    "        df = df.copy()\n",
    "        df['predicted_rating'] = predict_ratings(user_id, df['movieId'])\n",
    "    print(tabulate(df, headers='keys', tablefmt='pipe', showindex=show_index))\n",
    "\n",
    "\n",
    "user_id = 1\n",
    "movie_title = 'Toy Story (1995)'\n",
    "\n",
    "print(\"Popular Movies:\")\n",
    "display_recommendations(popularity_recommender(), user_id=user_id)\n",
    "\n",
    "print(\"\\nContent-based Recommendations for 'Toy Story (1995)':\")\n",
    "display_recommendations(content_based_recommender(movie_title), user_id=user_id)\n",
    "\n",
    "print(\"\\nCollaborative Filtering Recommendations for user 1:\")\n",
    "display_recommendations(collaborative_recommender(user_id), user_id=user_id)\n",
    "\n",
    "print(\"\\nMatrix Factorization Recommendations for user 1:\")\n",
    "display_recommendations(matrix_factorization_recommender(user_id), user_id=user_id)\n",
    "\n",
    "print(\"\\nHybrid Recommendations for user 1 and 'Toy Story (1995)':\")\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "loop = asyncio.get_event_loop()\n",
    "result = loop.run_until_complete(hybrid_recommender(user_id, movie_title))\n",
    "display_recommendations(result, user_id=user_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
